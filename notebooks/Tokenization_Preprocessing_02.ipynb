{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1dF2VtC2o6ltO4JJ2iU_bv3Ohj5tysPZq","timestamp":1771180161417}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e Metinlerde Tokenization ve Ã–n Ä°ÅŸleme\n"],"metadata":{"id":"EkLlr88Jh-YD"}},{"cell_type":"markdown","source":["Ä°nsanlar iÃ§in bir cÃ¼mleyi okumak ve kelimelere ayÄ±rmak son derece kolay ve doÄŸal bir sÃ¼reÃ§tir. Ancak bilgisayarlar iÃ§in metin, baÅŸlangÄ±Ã§ta sadece bir karakter dizisinden ibarettir:\n","\n","```\n","\"BugÃ¼nDoÄŸalDilÄ°ÅŸlemedersibaÅŸlÄ±yor\"\n","```\n","\n","Bilgisayar, bu metnin nerede baÅŸlayÄ±p nerede bittiÄŸini, hangi kÄ±smÄ±n kelime olduÄŸunu veya hangi kÄ±smÄ±n anlam taÅŸÄ±dÄ±ÄŸÄ±nÄ± kendiliÄŸinden bilemez. Bu nedenle, metni Ã¶nce daha kÃ¼Ã§Ã¼k ve anlamlÄ± parÃ§alara ayÄ±rmamÄ±z gerekir. Ä°ÅŸte bu iÅŸleme tokenization denir.\n","\n","**ğŸ¤– TÃ¼rkÃ§e neden Ã¶zellikle ilginÃ§ (ve biraz zor)?**\n","\n","TÃ¼rkÃ§e, eklemeli (agglutinative) bir dildir. Yani bir kelimeye birÃ§ok ek eklenerek Ã§ok uzun ve karmaÅŸÄ±k yapÄ±lar oluÅŸturulabilir:\n","\n","```\n","ev\n","evler\n","evleriniz\n","evlerinizden\n","evlerinizdenmiÅŸ\n","```\n","Hatta bazen tek bir kelime, bir cÃ¼mle kadar anlam taÅŸÄ±yabilir:\n","\n","```\n","BaÅŸlayamayacaklarÄ±mÄ±zdanmÄ±ÅŸsÄ±nÄ±z\n","```\n","\n","Ä°nsanlar iÃ§in bu normaldir. Ancak bilgisayarlar iÃ§in bu yapÄ±larÄ±n doÄŸru ÅŸekilde analiz edilebilmesi, doÄŸru bir tokenization sÃ¼reci gerektirir.\n","\n","\n"],"metadata":{"id":"e7DHEdLJkzGU"}},{"cell_type":"markdown","source":["Bu notebookâ€™ta TÃ¼rkÃ§e metinleri tokenize etmek iÃ§in **bazÄ± ek kÃ¼tÃ¼phaneler** kullanacaÄŸÄ±z. AÅŸaÄŸÄ±daki komutlar, gerekli kÃ¼tÃ¼phaneleri kurmak iÃ§in kullanÄ±lÄ±r:\n","\n","**ğŸ“¦ Kurulan KÃ¼tÃ¼phaneler ve AmaÃ§larÄ±**\n","\n","**1ï¸âƒ£ zemberek-python**\n","\n","Zemberek, TÃ¼rkÃ§e doÄŸal dil iÅŸleme iÃ§in geliÅŸtirilmiÅŸ gÃ¼Ã§lÃ¼ bir kÃ¼tÃ¼phanedir. TÃ¼rkÃ§eâ€™nin eklemeli yapÄ±sÄ±nÄ± anlayabilen Ã¶zel araÃ§lar iÃ§erir.\n","\n","[Zemberek](https://github.com/ahmetaa/zemberek-nlp)\n","\n","**2ï¸âƒ£ antlr4-python3-runtime**\n","\n","Bu kÃ¼tÃ¼phane, Zemberekâ€™in dÃ¼zgÃ¼n Ã§alÄ±ÅŸabilmesi iÃ§in gerekli olan bir baÄŸÄ±mlÄ±lÄ±ktÄ±r. Zemberek, metni analiz ederken belirli dil kurallarÄ±nÄ± kullanÄ±r. Bu kurallarÄ±n yorumlanabilmesi iÃ§in ANTLR altyapÄ±sÄ±na ihtiyaÃ§ duyulur.\n","\n","Biz bu kÃ¼tÃ¼phaneyi doÄŸrudan kullanmayacaÄŸÄ±z, ancak Zemberekâ€™in Ã§alÄ±ÅŸmasÄ± iÃ§in gereklidir.\n","\n","**3ï¸âƒ£ unicode_tr**\n","\n","Bu kÃ¼tÃ¼phane, TÃ¼rkÃ§e karakterlerle doÄŸru ÅŸekilde Ã§alÄ±ÅŸmamÄ±zÄ± saÄŸlar. Standart string iÅŸlemleri bazen TÃ¼rkÃ§e karakterleri doÄŸru ÅŸekilde iÅŸleyemez. unicode_tr kÃ¼tÃ¼phanesi, TÃ¼rkÃ§eâ€™ye Ã¶zel doÄŸru karakter dÃ¶nÃ¼ÅŸÃ¼mlerini yapmamÄ±zÄ± saÄŸlar."],"metadata":{"id":"6ALbb65tlS2Y"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"WN45bMUDrzrf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b1f5e2a7-7f58-46fb-b97b-67a46e6aed08","executionInfo":{"status":"ok","timestamp":1771180714997,"user_tz":-180,"elapsed":31816,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting zemberek-python\n","  Downloading zemberek_python-0.2.3-py3-none-any.whl.metadata (2.7 kB)\n","Collecting antlr4-python3-runtime==4.8 (from zemberek-python)\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from zemberek-python) (2.0.2)\n","Downloading zemberek_python-0.2.3-py3-none-any.whl (95.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.1/95.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=d7090b61d0acb96eb2d4151c93f5d8f68020693061601c6e2efbbd1c6d01893e\n","  Stored in directory: /root/.cache/pip/wheels/3e/92/b7/08c6a108fc5bf6370a7540d11bbe9befc99b7e045ac7558d49\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: antlr4-python3-runtime, zemberek-python\n","  Attempting uninstall: antlr4-python3-runtime\n","    Found existing installation: antlr4-python3-runtime 4.9.3\n","    Uninstalling antlr4-python3-runtime-4.9.3:\n","      Successfully uninstalled antlr4-python3-runtime-4.9.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","omegaconf 2.3.0 requires antlr4-python3-runtime==4.9.*, but you have antlr4-python3-runtime 4.8 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed antlr4-python3-runtime-4.8 zemberek-python-0.2.3\n","Collecting antlr4-python3-runtime==4.9\n","  Downloading antlr4-python3-runtime-4.9.tar.gz (114 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9-py3-none-any.whl size=140964 sha256=6715bcf1555480068526077d254e44b5b8c3f4a9995e6561553238432658d578\n","  Stored in directory: /root/.cache/pip/wheels/d0/1f/7e/508a418cc3ed72c4cc8fd321ecfd6bff9b89a51007e46d288c\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: antlr4-python3-runtime\n","  Attempting uninstall: antlr4-python3-runtime\n","    Found existing installation: antlr4-python3-runtime 4.8\n","    Uninstalling antlr4-python3-runtime-4.8:\n","      Successfully uninstalled antlr4-python3-runtime-4.8\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","zemberek-python 0.2.3 requires antlr4-python3-runtime==4.8, but you have antlr4-python3-runtime 4.9 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9\n","Collecting unicode_tr\n","  Downloading unicode_tr-0.6.1.tar.gz (1.1 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: unicode_tr\n","  Building wheel for unicode_tr (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unicode_tr: filename=unicode_tr-0.6.1-py3-none-any.whl size=2050 sha256=790f7ac41366e2b01abfcb5ea70e94a24a6507ce54a2a3fef1db317e069bbe8f\n","  Stored in directory: /root/.cache/pip/wheels/d3/6a/8b/1a73409da0601c67a2b1985b9dc55c7b689f28738d999dc8fc\n","Successfully built unicode_tr\n","Installing collected packages: unicode_tr\n","Successfully installed unicode_tr-0.6.1\n"]}],"source":["!pip install zemberek-python\n","!pip install antlr4-python3-runtime==4.9\n","!pip install unicode_tr"]},{"cell_type":"markdown","source":["Tokenization iÅŸlemini test etmek iÃ§in Ã¶rnek bir TÃ¼rkÃ§e metin (sample document) tanÄ±mlayalÄ±m:"],"metadata":{"id":"tfpbzdUviIoH"}},{"cell_type":"code","source":["sample_doc = \"\"\"\n","Ä°stanbul Gedik Ãœniversitesi Bilgisayar MÃ¼hendisliÄŸi Ã¶ÄŸrencisi BaÅŸak, NLP Ã¶devine baÅŸlamak iÃ§in bilgisayarÄ±nÄ± aÃ§tÄ±.\n","Ancak baÅŸlamadan Ã¶nce sadece 5 dakika dinlenmek istedi ve kendini 2 saat sonra YouTube'da \"Python mu Java mÄ±?\" videosu izlerken buldu.\n","\n","Proje teslim tarihi: 10 KasÄ±m 2026.\n","BaÅŸak, \"Bu sefer erken baÅŸlayacaÄŸÄ±m.\" dedi, fakat GitHub'a ilk commit'i 09 KasÄ±m 2026 saat 23:59'da attÄ±.\n","\n","KullandÄ±ÄŸÄ± bazÄ± teknolojiler:\n","Python, spaCy, Zemberek, TensorFlow, PyTorch ve tabii ki Stack Overflow.\n","\n","Ä°letiÅŸim bilgileri:\n","Web sitesi: www.basakbuluz.com\n","E-posta: basak.buluz@gmail.com\n","Hashtag: #yapayzeka #nlp #finalhaftasÄ±\n","\n","Not: YaklaÅŸÄ±k ~12 saatlik uykusuzluk sonrasÄ± yazÄ±lan kodlarÄ±n Ã§alÄ±ÅŸmasÄ± tamamen ÅŸans eseridir.\n","\"\"\"\n","\n","\n","sample_doc"],"metadata":{"id":"IZd5-v2ZoFzM","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1771180814283,"user_tz":-180,"elapsed":18,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}},"outputId":"324a964c-79ad-483e-9868-cad195b5a39e"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nÄ°stanbul Gedik Ãœniversitesi Bilgisayar MÃ¼hendisliÄŸi Ã¶ÄŸrencisi BaÅŸak, NLP Ã¶devine baÅŸlamak iÃ§in bilgisayarÄ±nÄ± aÃ§tÄ±.\\nAncak baÅŸlamadan Ã¶nce sadece 5 dakika dinlenmek istedi ve kendini 2 saat sonra YouTube\\'da \"Python mu Java mÄ±?\" videosu izlerken buldu.\\n\\nProje teslim tarihi: 10 KasÄ±m 2026.\\nBaÅŸak, \"Bu sefer erken baÅŸlayacaÄŸÄ±m.\" dedi, fakat GitHub\\'a ilk commit\\'i 09 KasÄ±m 2026 saat 23:59\\'da attÄ±.\\n\\nKullandÄ±ÄŸÄ± bazÄ± teknolojiler:\\nPython, spaCy, Zemberek, TensorFlow, PyTorch ve tabii ki Stack Overflow.\\n\\nÄ°letiÅŸim bilgileri:\\nWeb sitesi: www.basakbuluz.com\\nE-posta: basak.buluz@gmail.com\\nHashtag: #yapayzeka #nlp #finalhaftasÄ±\\n\\nNot: YaklaÅŸÄ±k ~12 saatlik uykusuzluk sonrasÄ± yazÄ±lan kodlarÄ±n Ã§alÄ±ÅŸmasÄ± tamamen ÅŸans eseridir.\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["**ğŸ“¦ NLTK kÃ¼tÃ¼phanesi**\n","\n","NLTK, DoÄŸal Dil Ä°ÅŸleme alanÄ±nda en eski ve en yaygÄ±n kullanÄ±lan kÃ¼tÃ¼phanelerden biridir. Ã–zellikle eÄŸitim amaÃ§lÄ± kullanÄ±mÄ± oldukÃ§a yaygÄ±ndÄ±r.\n","\n","**ğŸ“¥ Punkt tokenizer Modeli**\n","\n","Punkt, cÃ¼mle sÄ±nÄ±rlarÄ±nÄ± tespit etmek iÃ§in kullanÄ±lan Ã¶nceden eÄŸitilmiÅŸ bir modeldir.\n","\n","**ğŸ”§ Tokenization fonksiyonlarÄ±**\n","\n","NLTKâ€™nin en sÄ±k kullanÄ±lan iki tokenization fonksiyonunu iÃ§e aktarÄ±yoruz:\n","\n","* word_tokenize â†’ kelimelere ayÄ±rma\n","* sent_tokenize â†’ cÃ¼mlelere ayÄ±rma\n","\n","[NLTK](https://www.nltk.org/)"],"metadata":{"id":"F748aPkMoIeM"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","nltk.download('punkt_tab')\n","from nltk.tokenize import word_tokenize, sent_tokenize"],"metadata":{"id":"HjoDGhFviCWX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771181040696,"user_tz":-180,"elapsed":4123,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}},"outputId":"c27d605e-874c-4c15-8e5b-d8dc1c695ade"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]}]},{"cell_type":"markdown","source":["#### **sent_tokenize**\n","\n","* sample_doc â†’ tokenize etmek istediÄŸimiz metindir\n","* sent_tokenize() â†’ metni cÃ¼mlelere ayÄ±ran NLTK fonksiyonudur\n","* language=\"turkish\" â†’ metnin TÃ¼rkÃ§e olduÄŸunu belirtir\n","\n","Bu iÅŸlem sonucunda, metin artÄ±k bir cÃ¼mle listesi haline gelir"],"metadata":{"id":"uKceY016raYj"}},{"cell_type":"code","source":["sentences = sent_tokenize(sample_doc, language=\"turkish\")\n","\n","for sentence in sentences:\n","  print(sentence)\n","  print(\"\\n\")"],"metadata":{"id":"Mw7_kQmNiCY2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771181116721,"user_tz":-180,"elapsed":119,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}},"outputId":"36d54ecb-5647-49b8-9429-b3ba57e021e3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Ä°stanbul Gedik Ãœniversitesi Bilgisayar MÃ¼hendisliÄŸi Ã¶ÄŸrencisi BaÅŸak, NLP Ã¶devine baÅŸlamak iÃ§in bilgisayarÄ±nÄ± aÃ§tÄ±.\n","\n","\n","Ancak baÅŸlamadan Ã¶nce sadece 5 dakika dinlenmek istedi ve kendini 2 saat sonra YouTube'da \"Python mu Java mÄ±?\"\n","\n","\n","videosu izlerken buldu.\n","\n","\n","Proje teslim tarihi: 10 KasÄ±m 2026.\n","\n","\n","BaÅŸak, \"Bu sefer erken baÅŸlayacaÄŸÄ±m.\"\n","\n","\n","dedi, fakat GitHub'a ilk commit'i 09 KasÄ±m 2026 saat 23:59'da attÄ±.\n","\n","\n","KullandÄ±ÄŸÄ± bazÄ± teknolojiler:\n","Python, spaCy, Zemberek, TensorFlow, PyTorch ve tabii ki Stack Overflow.\n","\n","\n","Ä°letiÅŸim bilgileri:\n","Web sitesi: www.basakbuluz.com\n","E-posta: basak.buluz@gmail.com\n","Hashtag: #yapayzeka #nlp #finalhaftasÄ±\n","\n","Not: YaklaÅŸÄ±k ~12 saatlik uykusuzluk sonrasÄ± yazÄ±lan kodlarÄ±n Ã§alÄ±ÅŸmasÄ± tamamen ÅŸans eseridir.\n","\n","\n"]}]},{"cell_type":"markdown","source":["#### **word_tokenize**\n","\n","Metni sadece cÃ¼mlelere ayÄ±rmakla kalmÄ±yor, aynÄ± zamanda her bir cÃ¼mleyi kelimelere (tokenâ€™lara) da ayÄ±rÄ±yoruz. Bu iÅŸleme **word tokenization (kelime seviyesinde tokenization)** denir."],"metadata":{"id":"VkzhPQdDrXy1"}},{"cell_type":"code","source":["for sentence in sentences:\n","  print(sentence)\n","  words = word_tokenize(sentence)\n","  print(words)\n","  print(\"\\n\")"],"metadata":{"id":"xPOZHMkYrE90","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771181199228,"user_tz":-180,"elapsed":59,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}},"outputId":"c38e11bc-f647-49d9-a81d-7e58688eea1c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Ä°stanbul Gedik Ãœniversitesi Bilgisayar MÃ¼hendisliÄŸi Ã¶ÄŸrencisi BaÅŸak, NLP Ã¶devine baÅŸlamak iÃ§in bilgisayarÄ±nÄ± aÃ§tÄ±.\n","['Ä°stanbul', 'Gedik', 'Ãœniversitesi', 'Bilgisayar', 'MÃ¼hendisliÄŸi', 'Ã¶ÄŸrencisi', 'BaÅŸak', ',', 'NLP', 'Ã¶devine', 'baÅŸlamak', 'iÃ§in', 'bilgisayarÄ±nÄ±', 'aÃ§tÄ±', '.']\n","\n","\n","Ancak baÅŸlamadan Ã¶nce sadece 5 dakika dinlenmek istedi ve kendini 2 saat sonra YouTube'da \"Python mu Java mÄ±?\"\n","['Ancak', 'baÅŸlamadan', 'Ã¶nce', 'sadece', '5', 'dakika', 'dinlenmek', 'istedi', 've', 'kendini', '2', 'saat', 'sonra', \"YouTube'da\", '``', 'Python', 'mu', 'Java', 'mÄ±', '?', \"''\"]\n","\n","\n","videosu izlerken buldu.\n","['videosu', 'izlerken', 'buldu', '.']\n","\n","\n","Proje teslim tarihi: 10 KasÄ±m 2026.\n","['Proje', 'teslim', 'tarihi', ':', '10', 'KasÄ±m', '2026', '.']\n","\n","\n","BaÅŸak, \"Bu sefer erken baÅŸlayacaÄŸÄ±m.\"\n","['BaÅŸak', ',', '``', 'Bu', 'sefer', 'erken', 'baÅŸlayacaÄŸÄ±m', '.', \"''\"]\n","\n","\n","dedi, fakat GitHub'a ilk commit'i 09 KasÄ±m 2026 saat 23:59'da attÄ±.\n","['dedi', ',', 'fakat', 'GitHub', \"'\", 'a', 'ilk', 'commit', \"'\", 'i', '09', 'KasÄ±m', '2026', 'saat', \"23:59'da\", 'attÄ±', '.']\n","\n","\n","KullandÄ±ÄŸÄ± bazÄ± teknolojiler:\n","Python, spaCy, Zemberek, TensorFlow, PyTorch ve tabii ki Stack Overflow.\n","['KullandÄ±ÄŸÄ±', 'bazÄ±', 'teknolojiler', ':', 'Python', ',', 'spaCy', ',', 'Zemberek', ',', 'TensorFlow', ',', 'PyTorch', 've', 'tabii', 'ki', 'Stack', 'Overflow', '.']\n","\n","\n","Ä°letiÅŸim bilgileri:\n","Web sitesi: www.basakbuluz.com\n","E-posta: basak.buluz@gmail.com\n","Hashtag: #yapayzeka #nlp #finalhaftasÄ±\n","\n","Not: YaklaÅŸÄ±k ~12 saatlik uykusuzluk sonrasÄ± yazÄ±lan kodlarÄ±n Ã§alÄ±ÅŸmasÄ± tamamen ÅŸans eseridir.\n","['Ä°letiÅŸim', 'bilgileri', ':', 'Web', 'sitesi', ':', 'www.basakbuluz.com', 'E-posta', ':', 'basak.buluz', '@', 'gmail.com', 'Hashtag', ':', '#', 'yapayzeka', '#', 'nlp', '#', 'finalhaftasÄ±', 'Not', ':', 'YaklaÅŸÄ±k', '~12', 'saatlik', 'uykusuzluk', 'sonrasÄ±', 'yazÄ±lan', 'kodlarÄ±n', 'Ã§alÄ±ÅŸmasÄ±', 'tamamen', 'ÅŸans', 'eseridir', '.']\n","\n","\n"]}]},{"cell_type":"markdown","source":["## Zemberek\n","\n","**ğŸ‡¹ğŸ‡· TurkishSentenceExtractor nedir?**\n","\n","TurkishSentenceExtractor, TÃ¼rkÃ§e metinleri cÃ¼mlelere ayÄ±rmak (sentence tokenization) iÃ§in geliÅŸtirilmiÅŸ bir araÃ§tÄ±r.\n","\n","Daha Ã¶nce NLTK ile de cÃ¼mlelere ayÄ±rma iÅŸlemi yaptÄ±k. Ancak Zemberek, Ã¶zellikle TÃ¼rkÃ§e iÃ§in geliÅŸtirildiÄŸi iÃ§in bazÄ± durumlarda daha doÄŸru sonuÃ§lar verebilir.\n","\n","Ã‡Ã¼nkÃ¼ TÃ¼rkÃ§e:\n","\n","Eklemeli bir dildir\n","Ã–zel karakterler iÃ§erir (Ã§, ÄŸ, Ä±, Ã¶, ÅŸ, Ã¼)\n","Kesme iÅŸareti ile ayrÄ±lan ekler iÃ§erir (\"TÃ¼rkiye'nin\", \"Ankara'da\")\n","\n","Zemberek bu yapÄ±larÄ± daha iyi anlayacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r.\n","\n","**ğŸ¯ Neden Zemberek kullanÄ±yoruz?**\n","\n","Genel NLP kÃ¼tÃ¼phaneleri (NLTK, spaCy vb.) birÃ§ok dil iÃ§in Ã§alÄ±ÅŸÄ±r, ancak TÃ¼rkÃ§eâ€™ye Ã¶zel deÄŸildir.\n","\n","Zemberek ise:\n","\n","TÃ¼rkÃ§e iÃ§in Ã¶zel olarak geliÅŸtirilmiÅŸtir\n","TÃ¼rkÃ§e dil kurallarÄ±nÄ± bilir\n","TÃ¼rkÃ§e metinleri daha doÄŸru analiz edebilir\n","\n","Bu nedenle, TÃ¼rkÃ§e NLP uygulamalarÄ±nda Zemberek oldukÃ§a gÃ¼Ã§lÃ¼ bir araÃ§tÄ±r."],"metadata":{"id":"YOTwYJXsqDzv"}},{"cell_type":"code","source":["from zemberek import TurkishSentenceExtractor"],"metadata":{"id":"WwC6wfL8qMaa","executionInfo":{"status":"ok","timestamp":1771181294976,"user_tz":-180,"elapsed":240,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["#### zemberek - sentence tokenizer"],"metadata":{"id":"pq5F61Nzrkyj"}},{"cell_type":"code","source":["extractor = TurkishSentenceExtractor()\n","sentences = extractor.from_paragraph(sample_doc)\n","\n","for sentence in sentences:\n","  print(sentence)\n","  print(\"\\n\")"],"metadata":{"id":"q-qKOhXEqMgJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771181325239,"user_tz":-180,"elapsed":46,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}},"outputId":"214868b3-2ce6-486f-b624-09aa017d7c23"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Ä°stanbul Gedik Ãœniversitesi Bilgisayar MÃ¼hendisliÄŸi Ã¶ÄŸrencisi BaÅŸak, NLP Ã¶devine baÅŸlamak iÃ§in bilgisayarÄ±nÄ± aÃ§tÄ±.\n","\n","\n","Ancak baÅŸlamadan Ã¶nce sadece 5 dakika dinlenmek istedi ve kendini 2 saat sonra YouTube'da \"Python mu Java mÄ±?\n","\n","\n","\" videosu izlerken buldu.\n","\n","\n","Proje teslim tarihi: 10 KasÄ±m 2026.\n","BaÅŸak, \"Bu sefer erken baÅŸlayacaÄŸÄ±m.\n","\n","\n","\" dedi, fakat GitHub'a ilk commit'i 09 KasÄ±m 2026 saat 23:59'da attÄ±.\n","\n","\n","KullandÄ±ÄŸÄ± bazÄ± teknolojiler:\n","Python, spaCy, Zemberek, TensorFlow, PyTorch ve tabii ki Stack Overflow.\n","\n","Ä°letiÅŸim bilgileri:\n","Web sitesi: www.basakbuluz.com\n","E-posta: basak.buluz@gmail.com\n","Hashtag: #yapayzeka #nlp #finalhaftasÄ±\n","\n","Not: YaklaÅŸÄ±k ~12 saatlik uykusuzluk sonrasÄ± yazÄ±lan kodlarÄ±n Ã§alÄ±ÅŸmasÄ± tamamen ÅŸans eseridir.\n","\n","\n"]}]},{"cell_type":"markdown","source":["#### zemberek - word tokenizer"],"metadata":{"id":"2SevqPXLrnh1"}},{"cell_type":"code","source":["from zemberek import TurkishTokenizer\n","from zemberek.tokenization.token import Token\n","\n","tokenizer = TurkishTokenizer.builder().accept_all().ignore_types(\n","    [Token.Type.NewLine,\n","     Token.Type.SpaceTab,\n","     Token.Type.Punctuation]).build()\n","\n","\n","for sentence in sentences:\n","  print(sentence)\n","  tokens = tokenizer.tokenize(sentence)\n","  words = [token.content for token in tokens]\n","  print(words)\n","  print(\"\\n\")\n"],"metadata":{"id":"xjAVH0KeqMnq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771181388321,"user_tz":-180,"elapsed":53,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}},"outputId":"c0711a04-92b8-47f0-86a4-caa41257848d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Ä°stanbul Gedik Ãœniversitesi Bilgisayar MÃ¼hendisliÄŸi Ã¶ÄŸrencisi BaÅŸak, NLP Ã¶devine baÅŸlamak iÃ§in bilgisayarÄ±nÄ± aÃ§tÄ±.\n","['Ä°stanbul', 'Gedik', 'Ãœniversitesi', 'Bilgisayar', 'MÃ¼hendisliÄŸi', 'Ã¶ÄŸrencisi', 'BaÅŸak', 'NLP', 'Ã¶devine', 'baÅŸlamak', 'iÃ§in', 'bilgisayarÄ±nÄ±', 'aÃ§tÄ±']\n","\n","\n","Ancak baÅŸlamadan Ã¶nce sadece 5 dakika dinlenmek istedi ve kendini 2 saat sonra YouTube'da \"Python mu Java mÄ±?\n","['Ancak', 'baÅŸlamadan', 'Ã¶nce', 'sadece', '5', 'dakika', 'dinlenmek', 'istedi', 've', 'kendini', '2', 'saat', 'sonra', \"YouTube'da\", 'Python', 'mu', 'Java', 'mÄ±']\n","\n","\n","\" videosu izlerken buldu.\n","['videosu', 'izlerken', 'buldu']\n","\n","\n","Proje teslim tarihi: 10 KasÄ±m 2026.\n","BaÅŸak, \"Bu sefer erken baÅŸlayacaÄŸÄ±m.\n","['Proje', 'teslim', 'tarihi', '10', 'KasÄ±m', '2026.', 'BaÅŸak', 'Bu', 'sefer', 'erken', 'baÅŸlayacaÄŸÄ±m']\n","\n","\n","\" dedi, fakat GitHub'a ilk commit'i 09 KasÄ±m 2026 saat 23:59'da attÄ±.\n","['dedi', 'fakat', \"GitHub'a\", 'ilk', \"commit'i\", '09', 'KasÄ±m', '2026', 'saat', \"23:59'da\", 'attÄ±']\n","\n","\n","KullandÄ±ÄŸÄ± bazÄ± teknolojiler:\n","Python, spaCy, Zemberek, TensorFlow, PyTorch ve tabii ki Stack Overflow.\n","\n","Ä°letiÅŸim bilgileri:\n","Web sitesi: www.basakbuluz.com\n","E-posta: basak.buluz@gmail.com\n","Hashtag: #yapayzeka #nlp #finalhaftasÄ±\n","\n","Not: YaklaÅŸÄ±k ~12 saatlik uykusuzluk sonrasÄ± yazÄ±lan kodlarÄ±n Ã§alÄ±ÅŸmasÄ± tamamen ÅŸans eseridir.\n","['KullandÄ±ÄŸÄ±', 'bazÄ±', 'teknolojiler', 'Python', 'spaCy', 'Zemberek', 'TensorFlow', 'PyTorch', 've', 'tabii', 'ki', 'Stack', 'Overflow', 'Ä°letiÅŸim', 'bilgileri', 'Web', 'sitesi', 'www.basakbuluz.com', 'E-posta', 'basak.buluz@gmail.com', 'Hashtag', '#yapayzeka', '#nlp', '#finalhaftasÄ±', 'Not', 'YaklaÅŸÄ±k', '~12', 'saatlik', 'uykusuzluk', 'sonrasÄ±', 'yazÄ±lan', 'kodlarÄ±n', 'Ã§alÄ±ÅŸmasÄ±', 'tamamen', 'ÅŸans', 'eseridir']\n","\n","\n"]}]},{"cell_type":"code","source":["# TOKENIZATION\n","tokenizer = TurkishTokenizer.DEFAULT\n","\n","tokens = tokenizer.tokenize(\"Saat 12:00.\")\n","for token in tokens:\n","    print('Content = ', token.content)\n","    print('Type = ', token.type_.name)\n","    print('Start = ', token.start)\n","    print('Stop = ', token.end, '\\n')"],"metadata":{"id":"Aume7reB6pRD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771181437147,"user_tz":-180,"elapsed":7,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}},"outputId":"0f6a2df6-5d5f-4c05-912a-d35db07a25b8"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Content =  Saat\n","Type =  Word\n","Start =  0\n","Stop =  3 \n","\n","Content =  12:00\n","Type =  Time\n","Start =  5\n","Stop =  9 \n","\n","Content =  .\n","Type =  Punctuation\n","Start =  10\n","Stop =  10 \n","\n"]}]},{"cell_type":"markdown","source":["**ğŸ¯ Bu neden Ã§ok Ã¶nemli?**\n","\n","Ã‡Ã¼nkÃ¼ artÄ±k sadece kelimeleri deÄŸil, aynÄ± zamanda: **token tÃ¼rÃ¼nÃ¼, metin iÃ§indeki konumunu ve yapÄ±sÄ±nÄ±** da analiz edebiliyoruz.\n","\n","Bu bilgiler ÅŸu uygulamalarda kullanÄ±lÄ±r:\n","\n","* Named Entity Recognition (NER)\n","* Bilgi Ã§Ä±karÄ±mÄ±\n","* Metin hizalama (alignment)\n","* Metin iÅŸleme pipelineâ€™larÄ±"],"metadata":{"id":"FUDl9-L_pHIt"}},{"cell_type":"markdown","source":["### lower(): DÃ¶kÃ¼manÄ± kÃ¼Ã§Ã¼k harfe Ã§evirir\n","\n","**ğŸ¯ Neden lowercase iÅŸlemi yapÄ±yoruz?**\n","\n","Ã‡Ã¼nkÃ¼ bilgisayar iÃ§in:\n","```\n","Python\n","python\n","PYTHON\n","```\n","Ã¼Ã§Ã¼ farklÄ± kelimeler olarak algÄ±lanÄ±r.\n","Ama Ã§oÄŸu NLP uygulamasÄ±nda bunlarÄ±n aynÄ± kelime olduÄŸunu varsaymak isteriz.\n","Lowercase iÅŸlemi sayesinde:\n","```\n","Python â†’ python\n","PYTHON â†’ python\n","```\n","Hepsi aynÄ± forma dÃ¶nÃ¼ÅŸÃ¼r.\n","\n","Bu da:\n","\n","Kelime sayÄ±mÄ±nÄ± kolaylaÅŸtÄ±rÄ±r\n","Veri tutarlÄ±lÄ±ÄŸÄ±nÄ± artÄ±rÄ±r\n","Model performansÄ±nÄ± iyileÅŸtirir\n","\n","**âš ï¸ TÃ¼rkÃ§e iÃ§in Ã¶nemli bir detay**\n","\n","TÃ¼rkÃ§eâ€™de bazÄ± harflerin dÃ¶nÃ¼ÅŸÃ¼mÃ¼ Ä°ngilizceâ€™den farklÄ±dÄ±r:\n","```\n","I â†’ Ä±\n","Ä° â†’ i\n","```\n","Pythonâ€™Ä±n .lower() fonksiyonu genellikle doÄŸru Ã§alÄ±ÅŸÄ±r, ancak bazÄ± Ã¶zel durumlarda TÃ¼rkÃ§eâ€™ye Ã¶zel kÃ¼tÃ¼phaneler (Ã¶rneÄŸin **unicode_tr**) daha doÄŸru sonuÃ§ verebilir.\n","\n"],"metadata":{"id":"gjdD1n_Q5e6E"}},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","from unicode_tr import unicode_tr"],"metadata":{"id":"MV-DnwEHtBlP","executionInfo":{"status":"ok","timestamp":1771181670052,"user_tz":-180,"elapsed":42,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["sentences_lower = [sentence.lower() for sentence in sentences]\n","for sentence_lower in sentences_lower:\n","  print(sentence_lower)\n","  print(\"\\n\")"],"metadata":{"id":"R_AMnpt_lDP0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771181676009,"user_tz":-180,"elapsed":11,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}},"outputId":"a0bf6e37-f34a-465e-a3a0-6105b1e93d21"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["iÌ‡stanbul gedik Ã¼niversitesi bilgisayar mÃ¼hendisliÄŸi Ã¶ÄŸrencisi baÅŸak, nlp Ã¶devine baÅŸlamak iÃ§in bilgisayarÄ±nÄ± aÃ§tÄ±.\n","\n","\n","ancak baÅŸlamadan Ã¶nce sadece 5 dakika dinlenmek istedi ve kendini 2 saat sonra youtube'da \"python mu java mÄ±?\n","\n","\n","\" videosu izlerken buldu.\n","\n","\n","proje teslim tarihi: 10 kasÄ±m 2026.\n","baÅŸak, \"bu sefer erken baÅŸlayacaÄŸÄ±m.\n","\n","\n","\" dedi, fakat github'a ilk commit'i 09 kasÄ±m 2026 saat 23:59'da attÄ±.\n","\n","\n","kullandÄ±ÄŸÄ± bazÄ± teknolojiler:\n","python, spacy, zemberek, tensorflow, pytorch ve tabii ki stack overflow.\n","\n","iÌ‡letiÅŸim bilgileri:\n","web sitesi: www.basakbuluz.com\n","e-posta: basak.buluz@gmail.com\n","hashtag: #yapayzeka #nlp #finalhaftasÄ±\n","\n","not: yaklaÅŸÄ±k ~12 saatlik uykusuzluk sonrasÄ± yazÄ±lan kodlarÄ±n Ã§alÄ±ÅŸmasÄ± tamamen ÅŸans eseridir.\n","\n","\n"]}]},{"cell_type":"code","source":["sentences_lower = [unicode_tr(sentence).lower() for sentence in sentences]\n","for sentence_lower in sentences_lower:\n","  print(sentence_lower)\n","  print(\"\\n\")"],"metadata":{"id":"86MWdp8_lwnZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771181686826,"user_tz":-180,"elapsed":9,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}},"outputId":"106bcc40-7df8-4bd9-a128-2cdf9d195c76"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["istanbul gedik Ã¼niversitesi bilgisayar mÃ¼hendisliÄŸi Ã¶ÄŸrencisi baÅŸak, nlp Ã¶devine baÅŸlamak iÃ§in bilgisayarÄ±nÄ± aÃ§tÄ±.\n","\n","\n","ancak baÅŸlamadan Ã¶nce sadece 5 dakika dinlenmek istedi ve kendini 2 saat sonra youtube'da \"python mu java mÄ±?\n","\n","\n","\" videosu izlerken buldu.\n","\n","\n","proje teslim tarihi: 10 kasÄ±m 2026.\n","baÅŸak, \"bu sefer erken baÅŸlayacaÄŸÄ±m.\n","\n","\n","\" dedi, fakat github'a ilk commit'i 09 kasÄ±m 2026 saat 23:59'da attÄ±.\n","\n","\n","kullandÄ±ÄŸÄ± bazÄ± teknolojiler:\n","python, spacy, zemberek, tensorflow, pytorch ve tabii ki stack overflow.\n","\n","iletiÅŸim bilgileri:\n","web sitesi: www.basakbuluz.com\n","e-posta: basak.buluz@gmail.com\n","hashtag: #yapayzeka #nlp #finalhaftasÄ±\n","\n","not: yaklaÅŸÄ±k ~12 saatlik uykusuzluk sonrasÄ± yazÄ±lan kodlarÄ±n Ã§alÄ±ÅŸmasÄ± tamamen ÅŸans eseridir.\n","\n","\n"]}]},{"cell_type":"markdown","source":["**### clean_word():**\n","\n","Bu adÄ±mda, metin iÃ§indeki kelimeleri temizlemek (cleaning) iÃ§in kendi fonksiyonumuzu tanÄ±mlÄ±yoruz. Bu iÅŸlem, NLPâ€™de en Ã¶nemli Ã¶n iÅŸleme (pre-processing) adÄ±mlarÄ±ndan biridir.\n","\n","**ğŸ§¹ clean_word() fonksiyonu ne yapÄ±yor?**\n","\n","Bu fonksiyonun amacÄ±, bir kelimeyi NLP analizine uygun hale getirmek iÃ§in temizlemek ve normalize etmektir.\n","\n","GerÃ§ek dÃ¼nya metinleri genellikle ÅŸu tÃ¼r \"gÃ¼rÃ¼ltÃ¼ler\" iÃ§erir:\n","\n","```\n","\"Ankara'da\"\n","\"Python!!!\"\n","\"%100\"\n","\"e-posta:\"\n","\"#yapayzeka\"\n","```\n","\n","Bu karakterler Ã§oÄŸu zaman analiz iÃ§in gereksizdir.\n","Bu fonksiyon, kelimeyi sade ve analiz edilebilir hale getirir.\n","\n","**ğŸ”¹ AdÄ±m adÄ±m ne oluyor?**\n","\n","1ï¸âƒ£ TÃ¼rkÃ§eâ€™ye uygun ÅŸekilde kÃ¼Ã§Ã¼k harfe Ã§evirme\n","\n","2ï¸âƒ£ Ã–zel karakterleri temizleme\n","\n","3ï¸âƒ£ TÃ¼rkÃ§e alfabesi dÄ±ÅŸÄ±ndaki karakterleri kaldÄ±rma\n","\n"],"metadata":{"id":"gUjtm42DC6Q-"}},{"cell_type":"code","source":["import re\n","import string\n","\n","def clean_word(word):\n","  unwanted_list = [u\"&bull;\", u\"&lsquo;\",u\",\",u\"?\",u\"!\",u'\"',u\"'\",u\"â€˜\",u\"â€™\",u\"/\",u\"<\",u\">\",u\"|\",u\"â€œ\",\";\",\"&\",\"(\",\")\",\"=\",\"+\",\"-\",\"\\\\\",\"*\",\":\",\"~\",\"@\",\".\"]\n","  alpha_list = [u\"a\",u\"b\",u\"c\",u\"Ã§\",u\"d\",u\"e\",u\"f\",u\"g\",u\"ÄŸ\",u\"h\",u\"Ä±\",u\"i\",u\"j\",u\"k\",u\"l\",u\"m\",u\"n\",u\"o\",u\"Ã¶\",u\"p\",u\"q\",u\"r\",u\"s\",u\"ÅŸ\",u\"t\",u\"u\",u\"Ã¼\",u\"v\",u\"w\",u\"x\",u\"y\",u\"z\",\" \",]\n","\n","  # kÃ¼Ã§Ã¼k harfe Ã§eviriliyor\n","  word = unicode_tr(word).lower()\n","  txt = word.replace(u\"Ã¢\", u\"a\").lower()  # word.lower()\n","\n","  # farklÄ± karakterler siliniyor\n","  for unwanted_char in unwanted_list:\n","    # txt = txt.replace(uw,' ')\n","    # \"Ankara'da\" gibi tÄ±rnak kaldÄ±rÄ±ldÄ±ÄŸÄ±nda \"Ankara da\" ÅŸeklinde oluÅŸan aradaki boÅŸluk birleÅŸtirildi.\n","    txt = txt.replace(unwanted_char, \"\")\n","\n","  # geÃ§erli harf listesi dÄ±ÅŸÄ±ndaki harfler siliniyor\n","  chars = list(set(txt))\n","  for char in chars:\n","    if not char in alpha_list:\n","      txt = txt.replace(char, \"\")\n","\n","  return txt"],"metadata":{"id":"Niu25FtI5ZW6","executionInfo":{"status":"ok","timestamp":1771181822205,"user_tz":-180,"elapsed":18,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["clean_word(\"#yÃ¢payzeka\")"],"metadata":{"id":"7evwg_CQzHzB","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1771181824606,"user_tz":-180,"elapsed":50,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}},"outputId":"a1e498c5-b674-4508-beab-24faee1e9d63"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'yapayzeka'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["for sentence in sentences:\n","  print(sentence)\n","  tokens = tokenizer.tokenize(sentence)\n","  for token in tokens:\n","    print(clean_word(token.content))\n","  print(\"\\n\")"],"metadata":{"id":"qPnjRwscm23t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771181828268,"user_tz":-180,"elapsed":23,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}},"outputId":"b9c5a067-f72d-435b-c390-79f4c6d2c4d3"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Ä°stanbul Gedik Ãœniversitesi Bilgisayar MÃ¼hendisliÄŸi Ã¶ÄŸrencisi BaÅŸak, NLP Ã¶devine baÅŸlamak iÃ§in bilgisayarÄ±nÄ± aÃ§tÄ±.\n","istanbul\n","gedik\n","Ã¼niversitesi\n","bilgisayar\n","mÃ¼hendisliÄŸi\n","Ã¶ÄŸrencisi\n","baÅŸak\n","\n","nlp\n","Ã¶devine\n","baÅŸlamak\n","iÃ§in\n","bilgisayarÄ±nÄ±\n","aÃ§tÄ±\n","\n","\n","\n","Ancak baÅŸlamadan Ã¶nce sadece 5 dakika dinlenmek istedi ve kendini 2 saat sonra YouTube'da \"Python mu Java mÄ±?\n","ancak\n","baÅŸlamadan\n","Ã¶nce\n","sadece\n","\n","dakika\n","dinlenmek\n","istedi\n","ve\n","kendini\n","\n","saat\n","sonra\n","youtubeda\n","\n","python\n","mu\n","java\n","mÄ±\n","\n","\n","\n","\" videosu izlerken buldu.\n","\n","videosu\n","izlerken\n","buldu\n","\n","\n","\n","Proje teslim tarihi: 10 KasÄ±m 2026.\n","BaÅŸak, \"Bu sefer erken baÅŸlayacaÄŸÄ±m.\n","proje\n","teslim\n","tarihi\n","\n","\n","kasÄ±m\n","\n","baÅŸak\n","\n","\n","bu\n","sefer\n","erken\n","baÅŸlayacaÄŸÄ±m\n","\n","\n","\n","\" dedi, fakat GitHub'a ilk commit'i 09 KasÄ±m 2026 saat 23:59'da attÄ±.\n","\n","dedi\n","\n","fakat\n","githuba\n","ilk\n","commiti\n","\n","kasÄ±m\n","\n","saat\n","da\n","attÄ±\n","\n","\n","\n","KullandÄ±ÄŸÄ± bazÄ± teknolojiler:\n","Python, spaCy, Zemberek, TensorFlow, PyTorch ve tabii ki Stack Overflow.\n","\n","Ä°letiÅŸim bilgileri:\n","Web sitesi: www.basakbuluz.com\n","E-posta: basak.buluz@gmail.com\n","Hashtag: #yapayzeka #nlp #finalhaftasÄ±\n","\n","Not: YaklaÅŸÄ±k ~12 saatlik uykusuzluk sonrasÄ± yazÄ±lan kodlarÄ±n Ã§alÄ±ÅŸmasÄ± tamamen ÅŸans eseridir.\n","kullandÄ±ÄŸÄ±\n","bazÄ±\n","teknolojiler\n","\n","python\n","\n","spacy\n","\n","zemberek\n","\n","tensorflow\n","\n","pytorch\n","ve\n","tabii\n","ki\n","stack\n","overflow\n","\n","iletiÅŸim\n","bilgileri\n","\n","web\n","sitesi\n","\n","wwwbasakbuluzcom\n","eposta\n","\n","basakbuluzgmailcom\n","hashtag\n","\n","yapayzeka\n","nlp\n","finalhaftasÄ±\n","not\n","\n","yaklaÅŸÄ±k\n","\n","saatlik\n","uykusuzluk\n","sonrasÄ±\n","yazÄ±lan\n","kodlarÄ±n\n","Ã§alÄ±ÅŸmasÄ±\n","tamamen\n","ÅŸans\n","eseridir\n","\n","\n","\n"]}]},{"cell_type":"markdown","source":["## **remove_URL: DÃ¶kÃ¼mandan URL'leri kaldÄ±rÄ±n**\n","\n","Bu adÄ±mda, metin iÃ§indeki URLâ€™leri (web adreslerini) temizlemek iÃ§in Ã¶zel bir fonksiyon tanÄ±mlÄ±yoruz. URLâ€™ler genellikle NLP analizinde gereksiz gÃ¼rÃ¼ltÃ¼ oluÅŸturur ve Ã§oÄŸu durumda metinden kaldÄ±rÄ±lmalarÄ± gerekir."],"metadata":{"id":"E3IunhlqEG9O"}},{"cell_type":"code","source":["def remove_URL(text):\n","  # Remove URLs from a sample string\n","  pattern_url = r\"\"\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?Â«Â»â€œâ€â€˜â€™]))\"\"\"\n","  text_clean = re.sub(pattern_url, \"\", text)\n","\n","  return text_clean"],"metadata":{"id":"AMfLywfVDoK0","executionInfo":{"status":"ok","timestamp":1771181906625,"user_tz":-180,"elapsed":42,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["sentences_lower = [remove_URL(sentence) for sentence in sentences]\n","for sentence_lower in sentences_lower:\n","  print(sentence_lower)\n","  print(\"\\n\")"],"metadata":{"id":"5IpRdQkPnmnk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771181908568,"user_tz":-180,"elapsed":14,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}},"outputId":"c982e58a-081c-49dd-e4da-4eba285e7343"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Ä°stanbul Gedik Ãœniversitesi Bilgisayar MÃ¼hendisliÄŸi Ã¶ÄŸrencisi BaÅŸak, NLP Ã¶devine baÅŸlamak iÃ§in bilgisayarÄ±nÄ± aÃ§tÄ±.\n","\n","\n","Ancak baÅŸlamadan Ã¶nce sadece 5 dakika dinlenmek istedi ve kendini 2 saat sonra YouTube'da \"Python mu Java mÄ±?\n","\n","\n","\" videosu izlerken buldu.\n","\n","\n","Proje teslim tarihi: 10 KasÄ±m 2026.\n","BaÅŸak, \"Bu sefer erken baÅŸlayacaÄŸÄ±m.\n","\n","\n","\" dedi, fakat GitHub'a ilk commit'i 09 KasÄ±m 2026 saat 23:59'da attÄ±.\n","\n","\n","KullandÄ±ÄŸÄ± bazÄ± teknolojiler:\n","Python, spaCy, Zemberek, TensorFlow, PyTorch ve tabii ki Stack Overflow.\n","\n","Ä°letiÅŸim bilgileri:\n","Web sitesi: \n","E-posta: basak.buluz@gmail.com\n","Hashtag: #yapayzeka #nlp #finalhaftasÄ±\n","\n","Not: YaklaÅŸÄ±k ~12 saatlik uykusuzluk sonrasÄ± yazÄ±lan kodlarÄ±n Ã§alÄ±ÅŸmasÄ± tamamen ÅŸans eseridir.\n","\n","\n"]}]},{"cell_type":"markdown","source":["## **remove_email: DÃ¶kÃ¼manlardan e-posta adreslerini temizleyin**"],"metadata":{"id":"4gwvL3VjFuV_"}},{"cell_type":"markdown","source":["Bu fonksiyonun amacÄ±, metin iÃ§indeki tÃ¼m e-posta adreslerini tespit etmek ve silmektir.\n","\n","Ã–rneÄŸin ÅŸu tÃ¼r yapÄ±larÄ± kaldÄ±rabilir:\n","```\n","basak.buluz@gmail.com\n","student123@std.gedik.edu.tr\n","nlp.odev@universite.edu\n","```\n","\n"],"metadata":{"id":"cUny2VC5rBsi"}},{"cell_type":"code","source":["def remove_email(text):\n","  pattern_email = \"\\S*@\\S*\\s?\"\n","  text_clean = re.sub(pattern_email, \"\", text)\n","  return text_clean\n"],"metadata":{"id":"ksPgl7_v5ZZc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771182003741,"user_tz":-180,"elapsed":52,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}},"outputId":"fcd89a52-d2f8-462a-8eee-543ffd8caf6c"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["<>:2: SyntaxWarning: invalid escape sequence '\\S'\n","<>:2: SyntaxWarning: invalid escape sequence '\\S'\n","/tmp/ipython-input-1658067703.py:2: SyntaxWarning: invalid escape sequence '\\S'\n","  pattern_email = \"\\S*@\\S*\\s?\"\n"]}]},{"cell_type":"code","source":["sentences_lower = [remove_email(sentence) for sentence in sentences]\n","for sentence_lower in sentences_lower:\n","  print(sentence_lower)\n","  print(\"\\n\")"],"metadata":{"id":"a7bFfeJRnvgz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771182006433,"user_tz":-180,"elapsed":14,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}},"outputId":"081134ed-dc96-4353-f015-441c66fd7395"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Ä°stanbul Gedik Ãœniversitesi Bilgisayar MÃ¼hendisliÄŸi Ã¶ÄŸrencisi BaÅŸak, NLP Ã¶devine baÅŸlamak iÃ§in bilgisayarÄ±nÄ± aÃ§tÄ±.\n","\n","\n","Ancak baÅŸlamadan Ã¶nce sadece 5 dakika dinlenmek istedi ve kendini 2 saat sonra YouTube'da \"Python mu Java mÄ±?\n","\n","\n","\" videosu izlerken buldu.\n","\n","\n","Proje teslim tarihi: 10 KasÄ±m 2026.\n","BaÅŸak, \"Bu sefer erken baÅŸlayacaÄŸÄ±m.\n","\n","\n","\" dedi, fakat GitHub'a ilk commit'i 09 KasÄ±m 2026 saat 23:59'da attÄ±.\n","\n","\n","KullandÄ±ÄŸÄ± bazÄ± teknolojiler:\n","Python, spaCy, Zemberek, TensorFlow, PyTorch ve tabii ki Stack Overflow.\n","\n","Ä°letiÅŸim bilgileri:\n","Web sitesi: www.basakbuluz.com\n","E-posta: Hashtag: #yapayzeka #nlp #finalhaftasÄ±\n","\n","Not: YaklaÅŸÄ±k ~12 saatlik uykusuzluk sonrasÄ± yazÄ±lan kodlarÄ±n Ã§alÄ±ÅŸmasÄ± tamamen ÅŸans eseridir.\n","\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5_kBJNu-5Zb1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **NLTK - STOP WORDS**\n","\n","Bu adÄ±mda, TÃ¼rkÃ§e metinlerde Ã§ok sÄ±k geÃ§en ancak genellikle analiz aÃ§Ä±sÄ±ndan fazla anlam taÅŸÄ±mayan kelimeleri (stop words) kaldÄ±rabilmek iÃ§in gerekli listeyi yÃ¼klÃ¼yoruz.\n","\n","**ğŸ§© Stop word nedir?**\n","\n","Stop words, bir dilde Ã§ok sÄ±k kullanÄ±lan ancak genellikle metnin ana anlamÄ±na bÃ¼yÃ¼k katkÄ± saÄŸlamayan kelimelerdir.\n","\n","[trstop](https://github.com/ahmetax/trstop)"],"metadata":{"id":"b3hOeRLB3Jy5"}},{"cell_type":"code","source":["nltk.download('stopwords')\n","\n","from nltk.corpus import stopwords\n","\n","stopwords_list = set(stopwords.words('turkish'))"],"metadata":{"id":"qnxJFoEW5ZeR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771182115053,"user_tz":-180,"elapsed":70,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}},"outputId":"45a3ba1e-1919-46a5-f243-da7b6473140e"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["stopwords_list = stopwords.words('turkish')\n","\n","# TÃ¼m stop wordleri listele\n","for word in stopwords_list:\n","    print(word)"],"metadata":{"id":"J9SqYg6yw24_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771182158926,"user_tz":-180,"elapsed":17,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}},"outputId":"e4f34471-3007-4dea-e92e-1631e81d2deb"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["acaba\n","ama\n","aslÄ±nda\n","az\n","bazÄ±\n","belki\n","biri\n","birkaÃ§\n","birÅŸey\n","biz\n","bu\n","Ã§ok\n","Ã§Ã¼nkÃ¼\n","da\n","daha\n","de\n","defa\n","diye\n","eÄŸer\n","en\n","gibi\n","hem\n","hep\n","hepsi\n","her\n","hiÃ§\n","iÃ§in\n","ile\n","ise\n","kez\n","ki\n","kim\n","mÄ±\n","mu\n","mÃ¼\n","nasÄ±l\n","ne\n","neden\n","nerde\n","nerede\n","nereye\n","niÃ§in\n","niye\n","o\n","sanki\n","ÅŸey\n","siz\n","ÅŸu\n","tÃ¼m\n","ve\n","veya\n","ya\n","yani\n"]}]},{"cell_type":"code","source":["for sentence in sentences:\n","  print(sentence)\n","  tokens = tokenizer.tokenize(sentence)\n","  words = [token.content for token in tokens]\n","  print(words)\n","\n","  print(\"words_filtered\")\n","  words_filtered = []\n","  for w in words:\n","    if w not in stopwords_list:\n","      words_filtered.append(w)\n","\n","  print(words_filtered)\n","  print(\"\\n\")\n"],"metadata":{"id":"kEh7Qtot3QjA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771182116276,"user_tz":-180,"elapsed":58,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}},"outputId":"08521cca-0606-43a6-b582-6e0733b3860c"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Ä°stanbul Gedik Ãœniversitesi Bilgisayar MÃ¼hendisliÄŸi Ã¶ÄŸrencisi BaÅŸak, NLP Ã¶devine baÅŸlamak iÃ§in bilgisayarÄ±nÄ± aÃ§tÄ±.\n","['Ä°stanbul', 'Gedik', 'Ãœniversitesi', 'Bilgisayar', 'MÃ¼hendisliÄŸi', 'Ã¶ÄŸrencisi', 'BaÅŸak', ',', 'NLP', 'Ã¶devine', 'baÅŸlamak', 'iÃ§in', 'bilgisayarÄ±nÄ±', 'aÃ§tÄ±', '.']\n","words_filtered\n","['Ä°stanbul', 'Gedik', 'Ãœniversitesi', 'Bilgisayar', 'MÃ¼hendisliÄŸi', 'Ã¶ÄŸrencisi', 'BaÅŸak', ',', 'NLP', 'Ã¶devine', 'baÅŸlamak', 'bilgisayarÄ±nÄ±', 'aÃ§tÄ±', '.']\n","\n","\n","Ancak baÅŸlamadan Ã¶nce sadece 5 dakika dinlenmek istedi ve kendini 2 saat sonra YouTube'da \"Python mu Java mÄ±?\n","['Ancak', 'baÅŸlamadan', 'Ã¶nce', 'sadece', '5', 'dakika', 'dinlenmek', 'istedi', 've', 'kendini', '2', 'saat', 'sonra', \"YouTube'da\", '\"', 'Python', 'mu', 'Java', 'mÄ±', '?']\n","words_filtered\n","['Ancak', 'baÅŸlamadan', 'Ã¶nce', 'sadece', '5', 'dakika', 'dinlenmek', 'istedi', 'kendini', '2', 'saat', 'sonra', \"YouTube'da\", '\"', 'Python', 'Java', '?']\n","\n","\n","\" videosu izlerken buldu.\n","['\"', 'videosu', 'izlerken', 'buldu', '.']\n","words_filtered\n","['\"', 'videosu', 'izlerken', 'buldu', '.']\n","\n","\n","Proje teslim tarihi: 10 KasÄ±m 2026.\n","BaÅŸak, \"Bu sefer erken baÅŸlayacaÄŸÄ±m.\n","['Proje', 'teslim', 'tarihi', ':', '10', 'KasÄ±m', '2026.', 'BaÅŸak', ',', '\"', 'Bu', 'sefer', 'erken', 'baÅŸlayacaÄŸÄ±m', '.']\n","words_filtered\n","['Proje', 'teslim', 'tarihi', ':', '10', 'KasÄ±m', '2026.', 'BaÅŸak', ',', '\"', 'Bu', 'sefer', 'erken', 'baÅŸlayacaÄŸÄ±m', '.']\n","\n","\n","\" dedi, fakat GitHub'a ilk commit'i 09 KasÄ±m 2026 saat 23:59'da attÄ±.\n","['\"', 'dedi', ',', 'fakat', \"GitHub'a\", 'ilk', \"commit'i\", '09', 'KasÄ±m', '2026', 'saat', \"23:59'da\", 'attÄ±', '.']\n","words_filtered\n","['\"', 'dedi', ',', 'fakat', \"GitHub'a\", 'ilk', \"commit'i\", '09', 'KasÄ±m', '2026', 'saat', \"23:59'da\", 'attÄ±', '.']\n","\n","\n","KullandÄ±ÄŸÄ± bazÄ± teknolojiler:\n","Python, spaCy, Zemberek, TensorFlow, PyTorch ve tabii ki Stack Overflow.\n","\n","Ä°letiÅŸim bilgileri:\n","Web sitesi: www.basakbuluz.com\n","E-posta: basak.buluz@gmail.com\n","Hashtag: #yapayzeka #nlp #finalhaftasÄ±\n","\n","Not: YaklaÅŸÄ±k ~12 saatlik uykusuzluk sonrasÄ± yazÄ±lan kodlarÄ±n Ã§alÄ±ÅŸmasÄ± tamamen ÅŸans eseridir.\n","['KullandÄ±ÄŸÄ±', 'bazÄ±', 'teknolojiler', ':', 'Python', ',', 'spaCy', ',', 'Zemberek', ',', 'TensorFlow', ',', 'PyTorch', 've', 'tabii', 'ki', 'Stack', 'Overflow', '.', 'Ä°letiÅŸim', 'bilgileri', ':', 'Web', 'sitesi', ':', 'www.basakbuluz.com', 'E-posta', ':', 'basak.buluz@gmail.com', 'Hashtag', ':', '#yapayzeka', '#nlp', '#finalhaftasÄ±', 'Not', ':', 'YaklaÅŸÄ±k', '~12', 'saatlik', 'uykusuzluk', 'sonrasÄ±', 'yazÄ±lan', 'kodlarÄ±n', 'Ã§alÄ±ÅŸmasÄ±', 'tamamen', 'ÅŸans', 'eseridir', '.']\n","words_filtered\n","['KullandÄ±ÄŸÄ±', 'teknolojiler', ':', 'Python', ',', 'spaCy', ',', 'Zemberek', ',', 'TensorFlow', ',', 'PyTorch', 'tabii', 'Stack', 'Overflow', '.', 'Ä°letiÅŸim', 'bilgileri', ':', 'Web', 'sitesi', ':', 'www.basakbuluz.com', 'E-posta', ':', 'basak.buluz@gmail.com', 'Hashtag', ':', '#yapayzeka', '#nlp', '#finalhaftasÄ±', 'Not', ':', 'YaklaÅŸÄ±k', '~12', 'saatlik', 'uykusuzluk', 'sonrasÄ±', 'yazÄ±lan', 'kodlarÄ±n', 'Ã§alÄ±ÅŸmasÄ±', 'tamamen', 'ÅŸans', 'eseridir', '.']\n","\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"k5m7JoO-5YOp"},"execution_count":null,"outputs":[]}]}