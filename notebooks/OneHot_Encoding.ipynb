{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMl/o3KeLDfxc5cKf9Pxadn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# One-Hot Encoding NasÄ±l Ã‡alÄ±ÅŸÄ±r?\n","\n","One-Hot Encoding, metin verisini makine Ã¶ÄŸrenmesi algoritmalarÄ±nÄ±n anlayabileceÄŸi sayÄ±sal forma dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in kullanÄ±lan basit yÃ¶ntemlerden biridir.\n","\n","Bu yÃ¶ntemde **her kelime**, kendine Ã¶zel bir **binary (0 ve 1â€™lerden oluÅŸan) vektÃ¶r ile** temsil edilir.\n","\n","`AmaÃ§: Her kelimeyi benzersiz bir sayÄ±sal temsile dÃ¶nÃ¼ÅŸtÃ¼rmek`\n","\n","# One-Hot Encoding AdÄ±mlarÄ±\n","\n","**1ï¸âƒ£ Vocabulary (Kelime SÃ¶zlÃ¼ÄŸÃ¼) OluÅŸturma**\n","\n","Ä°lk adÄ±mda, metin iÃ§indeki **tÃ¼m benzersiz kelimeler** toplanÄ±r ve **bir vocabulary ** oluÅŸturulur.\n","\n","**Ã–rnek metin:**\n","```\n","\"NLP dersini seviyorum\"\n","\"NLP Ã§ok eÄŸlenceli\"\n","```\n","\n","**Vocabulary:**\n","```\n","[\"NLP\", \"dersini\", \"seviyorum\", \"Ã§ok\", \"eÄŸlenceli\"]\n","```\n","**Her kelimeye benzersiz bir indeks atanÄ±r:**\n","\n","```\n","NLP â†’ 0\n","dersini â†’ 1\n","seviyorum â†’ 2\n","Ã§ok â†’ 3\n","eÄŸlenceli â†’ 4\n","```\n","**2ï¸âƒ£ Vector Representation (VektÃ¶r Temsili)**\n","\n","Her kelime, vocabulary boyutu kadar uzunlukta bir binary vektÃ¶r ile temsil edilir.\n","\n","**Kurallar:**\n","\n","Kelimenin indeksine karÅŸÄ±lÄ±k gelen konum â†’ 1\n","\n","DiÄŸer tÃ¼m konumlar â†’ 0\n","\n","**Ã–rnek**\n","\n","`Vocabulary: [\"NLP\", \"dersini\", \"seviyorum\", \"Ã§ok\", \"eÄŸlenceli\"]`\n","\n","**Kelime: \"seviyorum\"**\n","\n","`VektÃ¶r temsili: [0, 0, 1, 0, 0]`\n"],"metadata":{"id":"hQ1-Bq9ecnzO"}},{"cell_type":"markdown","source":["# AdÄ±m AdÄ±m Uygulama\n","\n","**AdÄ±m 1: Gerekli KÃ¼tÃ¼phaneleri Ä°Ã§e Aktarma**\n","\n","Bu bÃ¶lÃ¼mde kullanacaÄŸÄ±mÄ±z kÃ¼tÃ¼phaneleri iÃ§e aktaracaÄŸÄ±z. Her birinin gÃ¶revi farklÄ±:\n","\n","**[NumPy (numpy):](https://www.geeksforgeeks.org/python/introduction-to-numpy/)** One-hot gibi vektÃ¶r temsillerini oluÅŸturmak iÃ§in kullanacaÄŸÄ±z. Yani â€œkelimeleri sayÄ±lara Ã§evirmeâ€ iÅŸinin **matematik tarafÄ±** burada.\n","\n","**[String (string):](https://www.geeksforgeeks.org/python/python-string/)** Metinden noktalama iÅŸaretlerini temizlemek iÃ§in iÅŸimize yarayacak. (Ã‡Ã¼nkÃ¼ ! , . ? gibi karakterler bazen gereksiz gÃ¼rÃ¼ltÃ¼ yaratabiliyor.)\n","\n","**[Matplotlib (matplotlib.pyplot): ](https://www.geeksforgeeks.org/python/pyplot-in-matplotlib/)** BazÄ± Ã§Ä±ktÄ±larÄ± gÃ¶rselleÅŸtirmek iÃ§in kullanacaÄŸÄ±z. Kodun ne Ã¼rettiÄŸini gÃ¶rmek her zaman daha keyifli ğŸ˜„"],"metadata":{"id":"StpZOS1kd-WQ"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"nKF2snq4cYWD","executionInfo":{"status":"ok","timestamp":1771782763281,"user_tz":-180,"elapsed":8,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}}},"outputs":[],"source":["import numpy as np\n","import string\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["**AdÄ±m 2: Corpus TanÄ±mlama**\n","\n","Corpus, NLP Ã§alÄ±ÅŸmalarÄ±nda kullanÄ±lan **metin koleksiyonudur**. Yani analiz etmek istediÄŸimiz tÃ¼m metinlerin bir araya gelmiÅŸ halidir.\n","\n","Bu corpus ÅŸunlardan oluÅŸabilir:\n","* CÃ¼mleler\n","* Paragraflar\n","* DokÃ¼manlar\n","* Tweetâ€™ler\n","* ÃœrÃ¼n yorumlarÄ±\n","* Haber metinleri\n","\n","Bizim Ã¶rneÄŸimizde corpus, birkaÃ§ basit cÃ¼mleden oluÅŸacak."],"metadata":{"id":"iB_DL_6Be6ht"}},{"cell_type":"code","source":["corpus = [\n","    \"I love NLP\",\n","    \"NLP is fun\",\n","    \"I love machine learning\",\n","    \"Deep learning is powerful\"\n","]"],"metadata":{"id":"IDxIQywfe1nW","executionInfo":{"status":"ok","timestamp":1771782918237,"user_tz":-180,"elapsed":10,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["**AdÄ±m 3: Metni Ã–n Ä°ÅŸleme (Preprocessing)**\n","\n","Metin verisini modele vermeden Ã¶nce, onu daha temiz ve tutarlÄ± hale getirmemiz gerekir. Bu iÅŸleme **text preprocessing (metin Ã¶n iÅŸleme)** denir.\n","\n","Bu adÄ±m, modelin metni daha doÄŸru ve verimli analiz etmesini saÄŸlar. Bu aÅŸamada Ã¼Ã§ temel iÅŸlem yapacaÄŸÄ±z:\n","\n","1ï¸âƒ£ **Metni KÃ¼Ã§Ã¼k Harfe DÃ¶nÃ¼ÅŸtÃ¼rme (Lowercasing)**\n","\n","AynÄ± kelimenin farklÄ± yazÄ±m biÃ§imlerini tek bir forma dÃ¶nÃ¼ÅŸtÃ¼rme amacÄ±yla yapacaÄŸÄ±z.\n","\n","2ï¸âƒ£ **Noktalama Ä°ÅŸaretlerini KaldÄ±rma (Remove Punctuation)**\n","\n","Noktalama iÅŸaretlerinin ayrÄ± token olarak algÄ±lanmasÄ±nÄ± Ã¶nlemek iÃ§in\n","\n","3ï¸âƒ£ **Metni Kelimelere AyÄ±rma (Tokenization)**\n","\n","AmaÃ§: CÃ¼mleyi kelimelere bÃ¶lmek."],"metadata":{"id":"IiodHVg0fkKz"}},{"cell_type":"code","source":["def preprocess_text(text):\n","    text = text.lower()\n","    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n","    return text.split()\n","tokenized_corpus = [preprocess_text(sentence) for sentence in corpus]"],"metadata":{"id":"zxy3UQyDfc92","executionInfo":{"status":"ok","timestamp":1771783094117,"user_tz":-180,"elapsed":41,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["**AdÄ±m 4: Vocabulary (Kelime SÃ¶zlÃ¼ÄŸÃ¼) OluÅŸturma**\n","\n","Bu adÄ±mda, corpus iÃ§indeki tÃ¼m benzersiz kelimeleri toplayarak bir **vocabulary (kelime sÃ¶zlÃ¼ÄŸÃ¼)** oluÅŸturacaÄŸÄ±z.\n","\n","Vocabulary, metni sayÄ±sal forma dÃ¶nÃ¼ÅŸtÃ¼rmenin en kritik adÄ±mlarÄ±ndan biridir. Ã‡Ã¼nkÃ¼ her kelime, bu sÃ¶zlÃ¼kteki indeksine gÃ¶re temsil edilecektir.\n","\n","**Neden sÄ±ralama (sorting) yapÄ±yoruz?**\n","\n","Vocabularyâ€™yi sÄ±ralamak, kelimelerin indekslerinin her zaman aynÄ± sÄ±rada olmasÄ±nÄ± saÄŸlar. Bu, modelin tutarlÄ± Ã§alÄ±ÅŸmasÄ± iÃ§in Ã¶nemlidir."],"metadata":{"id":"3uvCbGTigUXg"}},{"cell_type":"code","source":["vocabulary = sorted(set(word for sentence in tokenized_corpus for word in sentence))\n","word_to_index = {word: idx for idx, word in enumerate(vocabulary)}"],"metadata":{"id":"t1JL8yzSgH5m","executionInfo":{"status":"ok","timestamp":1771783242046,"user_tz":-180,"elapsed":44,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["**AdÄ±m 5: CÃ¼mleleri One-Hot Encoding ile Temsil Etme**\n","\n","Bu adÄ±mda, her kelimeyi daha Ã¶nce oluÅŸturduÄŸumuz **vocabulary kullanarak one-hot vektÃ¶rÃ¼ne** dÃ¶nÃ¼ÅŸtÃ¼receÄŸiz.\n","\n","1ï¸âƒ£ Her kelime iÃ§in, vocabulary boyutu kadar uzunlukta bir vektÃ¶r oluÅŸturulur.\n","2ï¸âƒ£ Kelimenin indeksine karÅŸÄ±lÄ±k gelen deÄŸeri 1 yapÄ±lÄ±r.\n","3ï¸âƒ£ CÃ¼mledeki tÃ¼m kelimeler iÃ§in vektÃ¶r oluÅŸturulur."],"metadata":{"id":"8Z8NVNZ_hBxE"}},{"cell_type":"code","source":["def one_hot_encode(sentence, word_to_index):\n","    vocab_size = len(word_to_index)\n","    encoded_sentence = []\n","    for word in sentence:\n","        vector = np.zeros(vocab_size, dtype=int)\n","        vector[word_to_index[word]] = 1\n","        encoded_sentence.append(vector)\n","    return np.array(encoded_sentence)\n","encoded_vectors = one_hot_encode(tokenized_corpus[0], word_to_index)"],"metadata":{"id":"B0cLohc3gsA7","executionInfo":{"status":"ok","timestamp":1771783417166,"user_tz":-180,"elapsed":51,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["print(\"Vocabulary:\")\n","print(vocabulary)\n","\n","print(\"\\nOne-Hot Encoded Vectors (First Sentence):\")\n","for word, vector in zip(tokenized_corpus[0], encoded_vectors):\n","    print(f\"{word}: {vector}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xoR095ZWhWxM","executionInfo":{"status":"ok","timestamp":1771783472509,"user_tz":-180,"elapsed":21,"user":{"displayName":"BaÅŸak Buluz KÃ¶meÃ§oÄŸlu","userId":"05750147927966471809"}},"outputId":"245f2080-9c65-4982-f10e-da5b894438ed"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary:\n","['deep', 'fun', 'i', 'is', 'learning', 'love', 'machine', 'nlp', 'powerful']\n","\n","One-Hot Encoded Vectors (First Sentence):\n","i: [0 0 1 0 0 0 0 0 0]\n","love: [0 0 0 0 0 1 0 0 0]\n","nlp: [0 0 0 0 0 0 0 1 0]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ZO5P9JwbhkSa"},"execution_count":null,"outputs":[]}]}